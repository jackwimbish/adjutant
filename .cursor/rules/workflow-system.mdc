---
description: 
globs: 
alwaysApply: false
---
# Workflow System

## Overview
Adjutant uses a manual workflow system for fetching and processing articles. The workflow has been changed from automatic (every 30 minutes) to user-triggered for better control and resource management. The system now includes intelligent workflow selection based on user profile existence for cost optimization.

## Workflow Trigger

### Manual Execution
- **UI Button**: "üì∞ Fetch Stories" in main window header
- **User Control**: Stories are fetched only when user clicks the button
- **Visual Feedback**: Button shows loading states and success/error messages

### Button States
```javascript
// Loading state
fetchBtn.textContent = '‚è≥ Fetching Stories...';
fetchBtn.disabled = true;

// Success state
fetchBtn.textContent = '‚úÖ Stories Fetching...';

// Error state
fetchBtn.textContent = '‚ùå Fetch Failed';

// Auto-reset after 3 seconds
setTimeout(() => {
  fetchBtn.textContent = 'üì∞ Fetch Stories';
  fetchBtn.disabled = false;
}, 3000);
```

## Workflow Architecture

### LangGraph-Style Processing
The workflow uses a multi-step approach with state management:

```typescript
interface AnalysisState {
  // Input data
  article: RSSItem;
  source: NewsSource;
  content: string;
  userConfig?: UserConfig;
  
  // Analysis results
  ai_summary?: string;
  ai_score?: number;
  ai_category?: string;
  
  // Quality control
  quality_issues: string[];
  retry_count: number;
  max_retries: number;
  
  // Content scraping
  rss_excerpt?: string;
  full_content_text?: string;
  content_source?: 'rss' | 'scraped' | 'failed';
  
  // Error handling
  error?: string;
  should_skip?: boolean;
}
```

### Processing Nodes

#### 1. Preprocessing (`src/workflows/nodes/preprocess.ts`)
- **Content Extraction**: Gets best available content from RSS
- **Content Cleaning**: Removes HTML and formatting
- **Length Validation**: Ensures minimum content length (50+ characters)
- **Truncation**: Limits content to 4000 characters for AI processing

#### 2. Analysis (`src/workflows/nodes/analyze.ts`)
- **OpenAI Integration**: Uses GPT-4o for article analysis
- **Prompt Engineering**: Specialized prompts for developer-focused content
- **JSON Response**: Structured output with score, category, and summary
- **Retry Logic**: Handles failures with improved prompts

#### 3. Quality Check (`src/workflows/nodes/quality-check.ts`)
- **Score Validation**: Ensures scores are between 1-10
- **Summary Validation**: Checks length and content quality
- **Category Validation**: Verifies valid category assignment
- **Retry Trigger**: Initiates retry with enhanced prompts if needed

#### 4. Content Scraping (`src/workflows/nodes/content-scraper.ts`)
- **Puppeteer Integration**: Headless browser for full article content
- **Readability Algorithm**: Mozilla Readability for clean text extraction
- **Fallback Handling**: Uses RSS content if scraping fails
- **Error Recovery**: Graceful degradation with detailed error logging

## AI Analysis Process

### Content Input
The AI receives up to 4000 characters of cleaned article content:

```typescript
const truncatedContent = cleanedContent.substring(0, CONFIG.AI_CONTENT_MAX_LENGTH); // 4000 chars
```

### Analysis Prompt
```typescript
const INITIAL_ANALYSIS_PROMPT = `
You are an AI news analyst for a software developer. Analyze the following article and provide a score from 1-10 on its relevance.

Scoring Criteria:
- High Score (8-10): Announce a new model, library, or tool; provide a technical tutorial.
- Medium Score (5-7): Discuss benchmark comparisons, best practices.
- Low Score (1-4): Focus on opinion, social commentary, or company funding.

Article Content:
{{CONTENT}}

Your Response (JSON):
{ "ai_score": <score_from_1_to_10>, "category": "<one of: 'New Tool', 'Tutorial', 'Research', 'Analysis', 'Opinion'>", "ai_summary": "<a one-sentence summary>" }
`;
```

### OpenAI Configuration
```typescript
const response = await openai.chat.completions.create({
  model: CONFIG.AI_MODEL, // 'gpt-4o'
  messages: [{ role: 'user', content: prompt }],
  temperature: 0.1,      // Low temperature for consistency
  max_tokens: 1000       // Limit response length
});
```

## Data Storage

### Article Data Structure
```typescript
interface ArticleData {
  // Core content
  url: string;
  title: string;
  author: string;
  rss_excerpt: string;        // Original RSS content
  full_content_text: string;  // Scraped full article
  
  // Metadata
  source_name: string;
  published_at: Date;
  fetched_at: Date;
  
  // AI Analysis
  ai_summary: string;
  ai_score: number;           // 1-10 relevance score
  ai_category: string;
  
  // User interaction
  relevant: boolean | null;  // null = unrated, true = relevant, false = not relevant
  rated_at?: Date;
  is_read: boolean;
  
  // Content tracking
  content_source: 'rss' | 'scraped' | 'failed';
  scraping_status: 'pending' | 'success' | 'failed';
  content_length: number;
}
```

### Firebase Integration
- **Document ID**: SHA-256 hash of article URL for deduplication
- **Real-time Updates**: UI updates immediately when articles are saved
- **Duplicate Prevention**: Existing articles are skipped during processing

## Error Handling

### Retry Logic
- **Maximum Retries**: 3 attempts per article
- **Enhanced Prompts**: Retry prompts include specific quality issues
- **Quality Validation**: Each analysis result is validated before acceptance

### Graceful Degradation
- **Scraping Failures**: Fall back to RSS content
- **API Failures**: Skip articles with detailed error logging
- **Network Issues**: Exponential backoff for rate limiting

### Logging System
```typescript
console.log(`‚úÖ Successfully processed article: ${article.title}`);
console.log(`‚ö†Ô∏è Skipping existing article: ${article.title}`);
console.error(`‚ùå Error processing article: ${error.message}`);
```

## Performance Considerations

### Rate Limiting
- **OpenAI API**: Respects rate limits with exponential backoff
- **Puppeteer**: Sequential processing to avoid overwhelming target sites
- **Firebase**: Batch operations where possible

### Resource Management
- **Browser Cleanup**: Puppeteer instances are properly closed
- **Memory Management**: Large content is truncated before processing
- **Process Isolation**: Workflow runs in separate process via spawn

## Configuration Integration

### User Configuration
The workflow requires user configuration for:
- **OpenAI API Key**: For article analysis
- **Firebase Config**: For data storage
- **Topic Description**: For content filtering (future enhancement)

### Runtime Validation
```typescript
if (!userConfig?.openai?.apiKey) {
  return {
    should_skip: true,
    error: 'No OpenAI API key available in configuration'
  };
}
```

## Workflow Selection Logic

### Profile-Based Routing
The system intelligently selects processing workflow based on user profile existence:

```typescript
// Main workflow selection in src/workflow.ts
async function analyzeArticle(article: RSSItem, userConfig: UserConfig): Promise<ArticleData> {
    const profile = await window.electronAPI.getProfile();
    
    if (!profile) {
        console.log('üìä No profile found - using topic-only analysis');
        return await analyzeArticleWithTopicOnly(article, userConfig);
    } else {
        console.log('üß† Profile found - using adaptive scoring');
        return await analyzeArticleWithAdaptiveScoring(article, userConfig);
    }
}
```

### Topic-Only Workflow (No Profile)
**Purpose**: Cost-effective processing for new users  
**Model**: GPT-4o-mini only  
**Cost per article**: ~$0.0008 (73% savings vs traditional)

```typescript
async function analyzeArticleWithTopicOnly(article: RSSItem, userConfig: UserConfig): Promise<ArticleData> {
    // 1. Content scraping (same as full workflow)
    const contentResult = await scrapeContent(article.url);
    
    // 2. Topic relevance check with GPT-4o-mini
    const isTopicRelevant = await checkTopicRelevance(
        article, 
        contentResult.content, 
        userConfig.appSettings.topicDescription
    );
    
    if (!isTopicRelevant) {
        return {
            ...article,
            ...contentResult,
            ai_score: null,
            ai_summary: 'Article not relevant to user topic interests',
            relevant: false,
            topic_filtered: true,
            topic_filtered_at: new Date()
        };
    }
    
    // 3. Basic summarization for topic-relevant articles
    const summary = await generateBasicSummary(article, contentResult.content);
    
    // 4. Default scoring for user rating
    return {
        ...article,
        ...contentResult,
        ai_summary: summary,
        ai_score: 5, // Default score - user will rate
        ai_category: 'Unclassified',
        relevant: null, // Unrated - appears in left column
        topic_filtered: false
    };
}
```

### Adaptive Scoring Workflow (With Profile)
**Purpose**: Personalized scoring based on user preferences  
**Models**: GPT-4o-mini (filtering) + GPT-4o (scoring)  
**Implementation**: [src/workflows/adaptive-scorer-workflow.ts](mdc:src/workflows/adaptive-scorer-workflow.ts)

Flow:
1. Topic relevance check (GPT-4o-mini)
2. Profile-based scoring (GPT-4o) - only if topic-relevant
3. Personalized categorization and summary

### Traditional Analysis Workflow (Legacy)
**Purpose**: Fallback when other workflows fail  
**Model**: GPT-4o for full analysis  
**Cost**: ~$0.0030 per article

## Workflow Cost Comparison

```
Topic-Only (No Profile):
- Content scraping: $0.0005
- GPT-4o-mini topic check: $0.0001  
- GPT-4o-mini summarization: $0.0002
- Total: $0.0008 per article

Adaptive Scoring (With Profile):
- Content scraping: $0.0005
- GPT-4o-mini topic filter: $0.0001
- GPT-4o profile scoring: $0.0020 (if relevant)
- Average: $0.0010 per article (assuming 60% relevance)

Traditional Analysis (Legacy):
- Content scraping: $0.0005
- GPT-4o full analysis: $0.0025  
- Total: $0.0030 per article

Cost Savings:
- Topic-only vs Traditional: 73% savings
- Adaptive vs Traditional: 67% savings
```

## Future Enhancements

### Planned Features
- **Dynamic Topic Updates**: User-editable topic descriptions via UI
- **Source Management**: Dynamic source configuration via UI
- **Scheduling Options**: Optional automatic fetching with user-defined intervals
- **Analytics**: Processing statistics and performance metrics
- **Multi-Topic Profiles**: Support for multiple topic interests per user
